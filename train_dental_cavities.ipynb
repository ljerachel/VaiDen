{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dental Cavities Detection - YOLOv5 Training Notebook\n",
        "\n",
        "This notebook trains a YOLOv5 model to detect dental cavities in X-ray images.\n",
        "\n",
        "## Overview\n",
        "- **Task**: Object Detection (Bounding Boxes)\n",
        "- **Dataset**: Dental Cavities (Custom)\n",
        "- **Model**: YOLOv5 (Small/Medium/Large)\n",
        "- **Output**: Trained model weights for cavity detection\n",
        "\n",
        "## Steps\n",
        "1. **Colab Setup** (Run this first if using Google Colab)\n",
        "2. Setup and Environment Check\n",
        "3. Dataset Preparation\n",
        "4. Training Configuration\n",
        "5. Start Training\n",
        "6. View Results\n",
        "7. Test Inference\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Colab Setup (Run This First!)\n",
        "\n",
        "**If you're using Google Colab**, run this cell first to set up the environment.  \n",
        "**If you're running locally**, skip this cell and go to \"Setup and Environment Check\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "CUDA device: Tesla T4\n",
            "CUDA memory: 15.83 GB\n",
            "\n",
            "Current directory: /content\n",
            "YOLOv5 root: /content\n",
            "\n",
            "‚ö†Ô∏è Setup check failed: No module named 'utils'\n",
            "Make sure you're running this notebook from the yolov5 directory\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Check PyTorch and CUDA\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# Check if we're in the right directory\n",
        "print(f\"\\nCurrent directory: {Path.cwd()}\")\n",
        "print(f\"YOLOv5 root: {Path(__file__).parent if '__file__' in globals() else Path.cwd()}\")\\\n",
        "    \n",
        "\n",
        "# Import YOLOv5 utilities\n",
        "try:\n",
        "    import utils\n",
        "    display = utils.notebook_init()  # checks\n",
        "    print(\"\\n‚úÖ Setup complete!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è Setup check failed: {e}\")\n",
        "    print(\"Make sure you're running this notebook from the yolov5 directory\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Setup and Environment Check\n",
        "\n",
        "Check if we have all required dependencies and verify the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "CUDA device: Tesla T4\n",
            "CUDA memory: 15.83 GB\n",
            "\n",
            "Current directory: /content\n",
            "‚ö†Ô∏è Warning: train.py not found!\n",
            "Make sure you're in the yolov5 directory or have run the Colab setup\n",
            "\n",
            "‚ö†Ô∏è Setup check failed: No module named 'utils'\n",
            "Try running the Colab setup cell above if you're in Colab\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Check PyTorch and CUDA\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# Check if we're in the right directory\n",
        "current_dir = Path.cwd()\n",
        "print(f\"\\nCurrent directory: {current_dir}\")\n",
        "\n",
        "# Check if we're in yolov5 directory (look for train.py)\n",
        "if Path(\"train.py\").exists():\n",
        "    print(\"‚úÖ Found train.py - we're in the YOLOv5 directory\")\n",
        "elif Path(\"yolov5/train.py\").exists():\n",
        "    print(\"‚ö†Ô∏è Found yolov5/train.py - changing to yolov5 directory...\")\n",
        "    %cd yolov5\n",
        "    print(f\"‚úÖ Changed to: {Path.cwd()}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Warning: train.py not found!\")\n",
        "    print(\"Make sure you're in the yolov5 directory or have run the Colab setup\")\n",
        "\n",
        "# Import YOLOv5 utilities\n",
        "try:\n",
        "    import utils\n",
        "    display = utils.notebook_init()  # checks\n",
        "    print(\"\\n‚úÖ Setup complete!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è Setup check failed: {e}\")\n",
        "    print(\"Try running the Colab setup cell above if you're in Colab\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Upload Dataset to Colab (Colab Only)\n",
        "\n",
        "**If using Google Colab**, you need to upload your dataset.  \n",
        "**If running locally**, skip this cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "OPTION 1: Direct Upload (Small files < 2GB)\n",
            "============================================================\n",
            "\n",
            "üì§ Upload your dataset:\n",
            "   1. If you have a zip file with your Dataset folder, upload it\n",
            "   2. If you already prepared the dataset, upload the 'datasets' folder as zip\n",
            "   3. Or upload the YAML config file if dataset is already in Colab\n",
            "\n",
            "üí° TIP: If upload widget doesn't appear, refresh the page and run this cell again\n",
            "============================================================\n",
            "\n",
            "‚è≥ Waiting for file upload...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c991dc2b-087c-4f11-a94b-1708b27c3559\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c991dc2b-087c-4f11-a94b-1708b27c3559\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ============================================\n",
        "# UPLOAD DATASET TO COLAB - OPTION 1: Direct Upload\n",
        "# ============================================\n",
        "# IMPORTANT: Run this cell fresh in your browser session!\n",
        "# If you see \"Upload widget is only available...\" error, \n",
        "# refresh the page and run this cell again.\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"=\"*60)\n",
        "    print(\"OPTION 1: Direct Upload (Small files < 2GB)\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nüì§ Upload your dataset:\")\n",
        "    print(\"   1. If you have a zip file with your Dataset folder, upload it\")\n",
        "    print(\"   2. If you already prepared the dataset, upload the 'datasets' folder as zip\")\n",
        "    print(\"   3. Or upload the YAML config file if dataset is already in Colab\")\n",
        "    print(\"\\nüí° TIP: If upload widget doesn't appear, refresh the page and run this cell again\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    from google.colab import files\n",
        "    from zipfile import ZipFile\n",
        "    from pathlib import Path\n",
        "    import shutil\n",
        "    \n",
        "    # This will show the upload widget - make sure to run this cell fresh!\n",
        "    print(\"\\n‚è≥ Waiting for file upload...\")\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    if uploaded:\n",
        "        print(f\"\\n‚úÖ Received {len(uploaded)} file(s)\")\n",
        "        \n",
        "        for filename in uploaded.keys():\n",
        "            print(f\"\\nüì¶ Processing {filename}...\")\n",
        "            \n",
        "            if filename.endswith('.zip'):\n",
        "                # Extract zip file\n",
        "                print(f\"   Extracting {filename}...\")\n",
        "                with ZipFile(filename, 'r') as zip_ref:\n",
        "                    zip_ref.extractall('.')\n",
        "                print(f\"   ‚úÖ Extracted {filename}\")\n",
        "                \n",
        "                # If it contains Dataset folder, prepare it\n",
        "                if Path(\"Dataset\").exists():\n",
        "                    print(\"\\nüîÑ Preparing dataset...\")\n",
        "                    !python prepare_dental_dataset.py\n",
        "                elif Path(\"datasets\").exists():\n",
        "                    print(\"   ‚úÖ Found prepared dataset folder\")\n",
        "                else:\n",
        "                    print(\"   ‚ö†Ô∏è No Dataset or datasets folder found in zip\")\n",
        "                    \n",
        "            elif filename.endswith('.yaml') or filename.endswith('.yml'):\n",
        "                # Copy YAML file to data directory\n",
        "                data_dir = Path(\"data\")\n",
        "                data_dir.mkdir(exist_ok=True)\n",
        "                shutil.copy(filename, \"data/dental_cavities.yaml\")\n",
        "                print(f\"   ‚úÖ Copied {filename} to data/dental_cavities.yaml\")\n",
        "            else:\n",
        "                print(f\"   ‚ö†Ô∏è Unknown file type: {filename}\")\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"‚úÖ Upload and processing complete!\")\n",
        "        print(\"=\"*60)\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è No files uploaded. Try running this cell again.\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping upload (running locally)\")\n",
        "    print(\"Make sure your dataset is in the correct location\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3b. Mount Google Drive (Alternative - For Large Datasets)\n",
        "\n",
        "**Recommended for large datasets!** Mount your Google Drive to access files stored there.\n",
        "\n",
        "**Why use Drive instead of upload?**\n",
        "- No file size limits (upload has ~2GB limit)\n",
        "- Faster for large datasets\n",
        "- Files persist between Colab sessions\n",
        "- No need to re-upload if you disconnect\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîó Mounting Google Drive...\n",
            "   (You'll need to authorize access - click the link and sign in)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1868778815.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üîó Mounting Google Drive...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"   (You'll need to authorize access - click the link and sign in)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n‚úÖ Drive mounted!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# MOUNT GOOGLE DRIVE (Alternative Method)\n",
        "# ============================================\n",
        "# Use this if your dataset is already in Google Drive\n",
        "# This is better for large datasets that take too long to upload\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    from pathlib import Path\n",
        "    import shutil\n",
        "    \n",
        "    print(\"üîó Mounting Google Drive...\")\n",
        "    print(\"   (You'll need to authorize access - click the link and sign in)\")\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    print(\"\\n‚úÖ Drive mounted!\")\n",
        "    print(\"\\nüìÅ Now you can access files from your Drive:\")\n",
        "    print(\"   Example: /content/drive/MyDrive/your_dataset_folder\")\n",
        "    \n",
        "    # Ask user for the path to their dataset in Drive\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Copy your dataset from Drive to Colab workspace\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Example: Copy from Drive to current directory\n",
        "    drive_dataset_path = input(\"\\nEnter path to your dataset in Drive (e.g., /content/drive/MyDrive/dental_cavities/Dataset): \").strip()\n",
        "    \n",
        "    if drive_dataset_path and Path(drive_dataset_path).exists():\n",
        "        print(f\"\\nüì¶ Copying dataset from {drive_dataset_path}...\")\n",
        "        \n",
        "        # Copy Dataset folder if it exists\n",
        "        if Path(drive_dataset_path).name == \"Dataset\" or (Path(drive_dataset_path) / \"Dataset\").exists():\n",
        "            source = Path(drive_dataset_path) if Path(drive_dataset_path).name == \"Dataset\" else Path(drive_dataset_path) / \"Dataset\"\n",
        "            dest = Path(\"Dataset\")\n",
        "            if source.exists():\n",
        "                if dest.exists():\n",
        "                    shutil.rmtree(dest)\n",
        "                shutil.copytree(source, dest)\n",
        "                print(f\"‚úÖ Copied Dataset folder\")\n",
        "                \n",
        "                # Prepare dataset\n",
        "                if Path(\"prepare_dental_dataset.py\").exists():\n",
        "                    print(\"\\nüîÑ Preparing dataset...\")\n",
        "                    !python prepare_dental_dataset.py\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Dataset folder not found at that path\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Path not found or not provided\")\n",
        "        print(\"\\nüí° Manual steps:\")\n",
        "        print(\"   1. Find your dataset in /content/drive/MyDrive/...\")\n",
        "        print(\"   2. Copy it to the current directory\")\n",
        "        print(\"   3. Run: !python prepare_dental_dataset.py\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping Drive mount (running locally)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3c. Download from URL (Alternative)\n",
        "\n",
        "If your dataset is hosted online (GitHub, Dropbox, etc.), download it directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# DOWNLOAD DATASET FROM URL\n",
        "# ============================================\n",
        "# Use this if your dataset is hosted online (GitHub, Dropbox, Google Drive share link, etc.)\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    import urllib.request\n",
        "    from zipfile import ZipFile\n",
        "    from pathlib import Path\n",
        "    \n",
        "    print(\"üåê Download dataset from URL\")\n",
        "    print(\"\\n   Supported:\")\n",
        "    print(\"   - Direct download links (.zip files)\")\n",
        "    print(\"   - Google Drive share links (need to convert)\")\n",
        "    print(\"   - GitHub releases\")\n",
        "    \n",
        "    # Example: Download from URL\n",
        "    dataset_url = input(\"\\nEnter dataset URL (or press Enter to skip): \").strip()\n",
        "    \n",
        "    if dataset_url:\n",
        "        print(f\"\\nüì• Downloading from {dataset_url}...\")\n",
        "        \n",
        "        # Download file\n",
        "        filename = \"dataset.zip\"\n",
        "        try:\n",
        "            urllib.request.urlretrieve(dataset_url, filename)\n",
        "            print(f\"‚úÖ Downloaded to {filename}\")\n",
        "            \n",
        "            # Extract\n",
        "            print(\"\\nüì¶ Extracting...\")\n",
        "            with ZipFile(filename, 'r') as zip_ref:\n",
        "                zip_ref.extractall('.')\n",
        "            print(\"‚úÖ Extracted\")\n",
        "            \n",
        "            # Prepare if Dataset folder exists\n",
        "            if Path(\"Dataset\").exists():\n",
        "                print(\"\\nüîÑ Preparing dataset...\")\n",
        "                !python prepare_dental_dataset.py\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "            print(\"\\nüí° Tips:\")\n",
        "            print(\"   - Make sure the URL is a direct download link\")\n",
        "            print(\"   - For Google Drive: Use 'Download' link, not 'View' link\")\n",
        "            print(\"   - For large files, consider using Drive mount instead\")\n",
        "    else:\n",
        "        print(\"‚è≠Ô∏è Skipped URL download\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping URL download (running locally)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking dataset...\n",
            "Dataset path exists: False\n",
            "YAML config exists: False\n",
            "\n",
            "‚ö†Ô∏è Dataset not found. Run prepare_dental_dataset.py first!\n",
            "   Command: python prepare_dental_dataset.py\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import yaml\n",
        "\n",
        "# Check dataset structure\n",
        "dataset_path = Path(\"datasets/dental_cavities\")\n",
        "yaml_path = Path(\"data/dental_cavities.yaml\")\n",
        "\n",
        "print(\"Checking dataset...\")\n",
        "print(f\"Dataset path exists: {dataset_path.exists()}\")\n",
        "print(f\"YAML config exists: {yaml_path.exists()}\")\n",
        "\n",
        "if dataset_path.exists():\n",
        "    train_images = len(list((dataset_path / \"images\" / \"train\").glob(\"*.*\")))\n",
        "    train_labels = len(list((dataset_path / \"labels\" / \"train\").glob(\"*.txt\")))\n",
        "    val_images = len(list((dataset_path / \"images\" / \"val\").glob(\"*.*\")))\n",
        "    val_labels = len(list((dataset_path / \"labels\" / \"val\").glob(\"*.txt\")))\n",
        "    \n",
        "    print(f\"\\nDataset statistics:\")\n",
        "    print(f\"  Train images: {train_images}\")\n",
        "    print(f\"  Train labels: {train_labels}\")\n",
        "    print(f\"  Val images: {val_images}\")\n",
        "    print(f\"  Val labels: {val_labels}\")\n",
        "    \n",
        "    if train_images == train_labels and val_images == val_labels:\n",
        "        print(\"\\n‚úÖ Dataset is ready!\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è Mismatch between images and labels!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Dataset not found. Run prepare_dental_dataset.py first!\")\n",
        "    print(\"   Command: python prepare_dental_dataset.py\")\n",
        "\n",
        "# Load and display YAML config\n",
        "if yaml_path.exists():\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    print(f\"\\nDataset configuration:\")\n",
        "    print(f\"  Path: {config.get('path')}\")\n",
        "    print(f\"  Classes: {config.get('nc')}\")\n",
        "    print(f\"  Class names: {config.get('names')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Training Configuration\n",
        "\n",
        "Configure your training parameters. Adjust these based on your system's memory and requirements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Configuration:\n",
            "  Dataset: data/dental_cavities.yaml\n",
            "  Weights: yolov5s.pt\n",
            "  Epochs: 10\n",
            "  Batch size: 4\n",
            "  Image size: 416\n",
            "  Device: Auto\n",
            "  Workers: 4\n",
            "  Project: runs/train/dental_cavities\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# TRAINING CONFIGURATION\n",
        "# ============================================\n",
        "# Adjust these parameters based on your needs\n",
        "\n",
        "# Dataset\n",
        "DATA_YAML = \"data/dental_cavities.yaml\"  # Path to dataset config\n",
        "\n",
        "# Model selection (choose one)\n",
        "# - yolov5n.pt: Nano (smallest, fastest, least memory)\n",
        "# - yolov5s.pt: Small (recommended for baseline)\n",
        "# - yolov5m.pt: Medium (better accuracy)\n",
        "# - yolov5l.pt: Large\n",
        "# - yolov5x.pt: Extra Large (best accuracy, most memory)\n",
        "WEIGHTS = \"yolov5s.pt\"  # Pretrained weights or '' for training from scratch\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 10  # Number of epochs (10 for baseline, 100+ for full training)\n",
        "BATCH_SIZE = 4  # Batch size (reduce if out of memory: try 2, 4, 8)\n",
        "IMG_SIZE = 416  # Image size (320, 416, 512, 640 - smaller uses less memory)\n",
        "\n",
        "# Advanced options\n",
        "DEVICE = \"\"  # Leave empty for auto-detect, or specify 'cpu', '0', '0,1,2,3'\n",
        "WORKERS = 4  # Number of dataloader workers (reduce if memory issues)\n",
        "PROJECT = \"runs/train\"  # Project directory\n",
        "NAME = \"dental_cavities\"  # Experiment name\n",
        "\n",
        "# Optional: Resume from checkpoint\n",
        "# RESUME = \"runs/train/dental_cavities/weights/last.pt\"  # Uncomment to resume\n",
        "RESUME = False\n",
        "\n",
        "print(\"Training Configuration:\")\n",
        "print(f\"  Dataset: {DATA_YAML}\")\n",
        "print(f\"  Weights: {WEIGHTS}\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Image size: {IMG_SIZE}\")\n",
        "print(f\"  Device: {DEVICE if DEVICE else 'Auto'}\")\n",
        "print(f\"  Workers: {WORKERS}\")\n",
        "print(f\"  Project: {PROJECT}/{NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Start Training\n",
        "\n",
        "Run the training. This may take a while depending on your configuration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'train'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1774478251.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import training module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Prepare training arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'train'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Import training module\n",
        "import train\n",
        "from utils.callbacks import Callbacks\n",
        "\n",
        "# Prepare training arguments\n",
        "training_args = {\n",
        "    'data': DATA_YAML,\n",
        "    'weights': WEIGHTS,\n",
        "    'epochs': EPOCHS,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'imgsz': IMG_SIZE,\n",
        "    'device': DEVICE,\n",
        "    'workers': WORKERS,\n",
        "    'project': PROJECT,\n",
        "    'name': NAME,\n",
        "    'exist_ok': True,  # Overwrite existing experiment\n",
        "}\n",
        "\n",
        "# Add resume if specified\n",
        "if RESUME:\n",
        "    training_args['resume'] = RESUME\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Run training\n",
        "try:\n",
        "    opt = train.run(**training_args)\n",
        "    print(\"\\n‚úÖ Training completed!\")\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n‚ö†Ô∏è Training interrupted by user\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Training failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. View Training Results\n",
        "\n",
        "Display training results, metrics, and visualizations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "# Find the latest training run\n",
        "runs_dir = Path(PROJECT) / NAME\n",
        "if not runs_dir.exists():\n",
        "    # Try to find the latest exp directory\n",
        "    exp_dirs = sorted(Path(PROJECT).glob(\"exp*\"), key=lambda x: x.stat().st_mtime, reverse=True)\n",
        "    if exp_dirs:\n",
        "        runs_dir = exp_dirs[0]\n",
        "        print(f\"Using latest run: {runs_dir}\")\n",
        "\n",
        "if runs_dir.exists():\n",
        "    print(f\"Results directory: {runs_dir}\")\n",
        "    \n",
        "    # Display training results\n",
        "    results_img = runs_dir / \"results.png\"\n",
        "    if results_img.exists():\n",
        "        print(\"\\nüìä Training Results:\")\n",
        "        display(Image(str(results_img), width=800))\n",
        "    \n",
        "    # Display confusion matrix\n",
        "    confusion_img = runs_dir / \"confusion_matrix.png\"\n",
        "    if confusion_img.exists():\n",
        "        print(\"\\nüìà Confusion Matrix:\")\n",
        "        display(Image(str(confusion_img), width=600))\n",
        "    \n",
        "    # Display validation batch\n",
        "    val_batch = runs_dir / \"val_batch0_labels.jpg\"\n",
        "    if val_batch.exists():\n",
        "        print(\"\\nüîç Validation Batch (Ground Truth):\")\n",
        "        display(Image(str(val_batch), width=600))\n",
        "    \n",
        "    val_pred = runs_dir / \"val_batch0_pred.jpg\"\n",
        "    if val_pred.exists():\n",
        "        print(\"\\nüéØ Validation Batch (Predictions):\")\n",
        "        display(Image(str(val_pred), width=600))\n",
        "    \n",
        "    # Show best weights location\n",
        "    best_weights = runs_dir / \"weights\" / \"best.pt\"\n",
        "    last_weights = runs_dir / \"weights\" / \"last.pt\"\n",
        "    \n",
        "    print(f\"\\nüíæ Model Weights:\")\n",
        "    print(f\"  Best model: {best_weights}\")\n",
        "    print(f\"  Last model: {last_weights}\")\n",
        "    print(f\"  Best model exists: {best_weights.exists()}\")\n",
        "    print(f\"  Last model exists: {last_weights.exists()}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"‚ùå Results directory not found: {runs_dir}\")\n",
        "    print(\"Training may not have completed successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test Inference on Sample Images\n",
        "\n",
        "Test your trained model on validation images or new images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from IPython.display import Image, display\n",
        "import detect\n",
        "\n",
        "# Find the best weights\n",
        "weights_path = Path(PROJECT) / NAME / \"weights\" / \"best.pt\"\n",
        "if not weights_path.exists():\n",
        "    # Try last.pt\n",
        "    weights_path = Path(PROJECT) / NAME / \"weights\" / \"last.pt\"\n",
        "\n",
        "if weights_path.exists():\n",
        "    print(f\"Using weights: {weights_path}\")\n",
        "    \n",
        "    # Test on validation images\n",
        "    val_images_dir = Path(\"datasets/dental_cavities/images/val\")\n",
        "    \n",
        "    if val_images_dir.exists():\n",
        "        # Get a few sample images\n",
        "        sample_images = list(val_images_dir.glob(\"*.*\"))[:5]\n",
        "        \n",
        "        if sample_images:\n",
        "            print(f\"\\nTesting on {len(sample_images)} sample images...\")\n",
        "            \n",
        "            # Run detection\n",
        "            detect.run(\n",
        "                weights=str(weights_path),\n",
        "                source=str(sample_images[0].parent),  # Directory\n",
        "                imgsz=IMG_SIZE,\n",
        "                conf=0.25,  # Confidence threshold\n",
        "                save_txt=True,\n",
        "                save_conf=True,\n",
        "                project=\"runs/detect\",\n",
        "                name=\"dental_cavities_test\",\n",
        "                exist_ok=True\n",
        "            )\n",
        "            \n",
        "            # Display results\n",
        "            results_dir = Path(\"runs/detect/dental_cavities_test\")\n",
        "            if results_dir.exists():\n",
        "                result_images = list(results_dir.glob(\"*.jpg\"))[:5]\n",
        "                print(f\"\\nüì∏ Detection Results:\")\n",
        "                for img_path in result_images:\n",
        "                    display(Image(str(img_path), width=400))\n",
        "        else:\n",
        "            print(\"No images found in validation directory\")\n",
        "    else:\n",
        "        print(f\"Validation images directory not found: {val_images_dir}\")\n",
        "else:\n",
        "    print(f\"‚ùå Model weights not found: {weights_path}\")\n",
        "    print(\"Training may not have completed successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Continue Training (Optional)\n",
        "\n",
        "If you want to train for more epochs, you can resume from the last checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Uncomment and modify to continue training\n",
        "# This will resume from the last checkpoint and train for additional epochs\n",
        "\n",
        "# CONTINUE_EPOCHS = 50  # Additional epochs to train\n",
        "# LAST_WEIGHTS = f\"{PROJECT}/{NAME}/weights/last.pt\"\n",
        "# \n",
        "# if Path(LAST_WEIGHTS).exists():\n",
        "#     print(f\"Resuming training from {LAST_WEIGHTS}\")\n",
        "#     train.run(\n",
        "#         data=DATA_YAML,\n",
        "#         weights=LAST_WEIGHTS,\n",
        "#         epochs=EPOCHS + CONTINUE_EPOCHS,\n",
        "#         batch_size=BATCH_SIZE,\n",
        "#         imgsz=IMG_SIZE,\n",
        "#         device=DEVICE,\n",
        "#         workers=WORKERS,\n",
        "#         project=PROJECT,\n",
        "#         name=NAME,\n",
        "#         resume=True,\n",
        "#         exist_ok=True\n",
        "#     )\n",
        "# else:\n",
        "#     print(f\"Last weights not found: {LAST_WEIGHTS}\")\n",
        "\n",
        "print(\"To continue training, uncomment the code above and adjust CONTINUE_EPOCHS\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips and Troubleshooting\n",
        "\n",
        "### Memory Issues\n",
        "- Reduce `BATCH_SIZE` to 2 or 4\n",
        "- Reduce `IMG_SIZE` to 320 or 416\n",
        "- Use `yolov5n.pt` instead of `yolov5s.pt`\n",
        "- Reduce `WORKERS` to 2\n",
        "\n",
        "### Better Results\n",
        "- Train for more epochs (100+)\n",
        "- Use larger model (`yolov5m.pt` or `yolov5l.pt`)\n",
        "- Use larger image size (640)\n",
        "- Ensure dataset quality and annotation accuracy\n",
        "\n",
        "### Quick Baseline\n",
        "- Use 10 epochs for quick testing\n",
        "- Use smaller model and image size\n",
        "- Check if training is working before full training\n",
        "\n",
        "### Resume Training\n",
        "- Set `RESUME = \"runs/train/dental_cavities/weights/last.pt\"` to continue from checkpoint\n",
        "- Or use the \"Continue Training\" section above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips and Troubleshooting\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
